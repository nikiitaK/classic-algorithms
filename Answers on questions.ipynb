{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "112fa839",
   "metadata": {},
   "source": [
    "## ПИШ 2023. Блок 2 «Машинное обучение». Ответы на вопросы аттестации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff1cff5",
   "metadata": {},
   "source": [
    "## 1. Объясните, как вычисляется качество модели с задачей классификации: назовите основные и вторичные метрики, приведите пример.\n",
    "\n",
    "Для рассмотрения всех возможных вариантов используется матрица 2x2 (\"матрица ошибок\"), в которой отражены все возможные сочетания предсказанных и реальных значений целевой переменной. В случае работы с булевой классификацией можно условиться, что class_1 = Positive, class_2 = Negative. В случае мульти классификации тоже можно использовать 2x2 таблицу, тогда необходимо строить её для каждого класса отдельно, а разделение будет следующим: class_1 = Positive, all_other_class = Negative.\n",
    "\n",
    "|| Positive (Prediction) | Negative (Prediction) |\n",
    "|---| ---------- | --------- | \n",
    "|Positive (data)| (TP) True Positive | (FN) False Negative |\n",
    "|Negative (data)|(FP) False Positive | (TN) True Negative |\n",
    "\n",
    "<br><br>**Основные метрики оценки моделей классификации:**\n",
    "1. Accuracy - доля верных ответов. Особенность: нельзя использовать в задачах с неравными классами.\n",
    "$$Accuracy = \\frac{TP+TN}{TP+FP+FN+TN}$$\n",
    "\n",
    "2. Prescision (Точность) - доля объектов действительно принадлежащих к классу относительно всех объектов которые система отнесла к этому классу. Устойчива к False Positive.\n",
    "$$Prescision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "3. Recall (Полнота) - доля объектов, реально относящихся к положительному классу, которая предсказана верно. Устойчива к False Negative.\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "4. F1-Score (\"эф-мера\") - среднее гармоническое между Prescision и Recall. F-мера достигает максимума при максимальной полноте и точности, и близка к нулю, если один из аргументов близок к нулю. По умолчанию вклад точности и полноты равен. \n",
    "<br>\n",
    "$$F_1 = \\frac{TP}{TP+\\frac{FP+FN}{2}} = 2* \\frac{Recall*Prescision}{Recall+Prescision}$$\n",
    "Если необходимо дать точности или полноте больший вес, то используется $F_\\beta$ (при 0<β<1 приоритет точности, при β>1 приоритет полноты, при β=1 - приоритеты равны)\n",
    "$$F_\\beta = (1+\\beta)^2* \\frac{Recall*Prescision}{Recall+Prescision*\\beta^2}$$\n",
    "\n",
    "\n",
    "**Вторичные метрики:**\n",
    "1. ErrorRate - доля ошибочных классификаций (как и Accuracy не учитывает дисбаланс классов)\n",
    "$$ErrorRate = \\frac{FP+FN}{TP+FP+FN+TN}$$\n",
    "\n",
    "2. Macro avg, weighted avg, samples - мультиклассовые показатели: \n",
    "- \"macro avg\" - вычисляет среднее значение мультиклассового показателя (prescision, recall, f1);\n",
    "$$macro Avg(prescision) = \\frac{\\sum_{i=0}^n prescision_i}{N}$$\n",
    "- \"weighted avg\" вычисляя среднее взвешенное значение мультиклассовых показателей;\n",
    "$$weighted Avg(recall) = \\frac{support_i * \\sum_{i=0}^n recall_i}{support_{all}}$$\n",
    "- \"samples\" - вычисляет метрику по истинным классам.\n",
    "\n",
    "3. ROC-кривая - график, который построен на двух осях: TPR (true positive rate) и FPR (false positive rate). Используется  чтобы выбрать порог отсечения между классами.\n",
    "\n",
    "TPR (true positive rate) - доля положительных объектов, правильно предсказанных положительными:\n",
    "<br>$$TPR = \\frac{TP}{TP+FN}$$\n",
    "FPR (false positive rate) – доля отрицательных объектов, неправильно предсказанных положительными:\n",
    "$$TPR = \\frac{FP}{FP+TN}$$\n",
    "\n",
    "4. AUC (Area Under Curve) - площадь под ROC-кривой. Чем лучше классификатор разделяет два класса, тем больше площадь под ROC-кривой.\n",
    "\n",
    "#### Пример\n",
    "|| Positive| Negative|\n",
    "|---| ---------- | --------- | \n",
    "|Positive| 280 | 14 |\n",
    "|Negative| 20 | 60 |\n",
    "\n",
    "Accuracy = 0.9  \n",
    "Prescision = 0.93  \n",
    "Recall = 0.95  \n",
    "$F_1$ = 0,91  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b358a83",
   "metadata": {},
   "source": [
    "## 2. Что такое тестовый набор данных (test set) и для чего он нужен?\n",
    "\n",
    "Тестовый набор содержит данные, которые модель ещё не видела, обычно он формируется путем случайной выборки из исходного набора данных.\n",
    "\n",
    "Цель применения тестового множества – проверить, как обученная модель будет работать с новыми данными, т.е. приобрела ли она обобщающую способность.\n",
    "\n",
    "Если ошибки на тестовом и обучающем множествах достаточно малы, то это позволяет утверждать, что модель приобрела способность к обобщению и может использоваться для работы с новыми данными. Если малая ошибка достигнута только на обучающем множестве, а на тестовом она велика, это говорит о переобученности модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153da82e",
   "metadata": {},
   "source": [
    "## 3. Каково назначение валидационного множества данных (validation set)?\n",
    "\n",
    "Валидационный сет необходим, чтобы во время обучения модели можно было перебрать и сравнить разные обучающие алгоритмы, параметры, гиперпараметры. \n",
    "\n",
    "По сути валидационный сет очень похож на тестовый: \n",
    "- меньше обучающего;\n",
    "- позволяет оценить качество модели на новых данных. \n",
    "\n",
    "Хотя есть и отличия:\n",
    "- во время использования валидационного сета параметры модели можно и нужно менять, чтобы выбрать наилучшие;\n",
    "- тестовый сет используется лишь после окончания обучения модели, так как он нужен для того чтобы оценить готовую модель;\n",
    "- тестовый сет даёт полностью независимую оценку, данные же валидационного сета постепенно просачиваются в модель во время обучения.\n",
    "\n",
    "Валидационный сет используется не всегда: когда количество данных слишком мало, то лучше использовать лишь учебный и тестовый сеты, но при использовании большого количества данных для обучения модели стоит выделить и валидационный сет, он позволит подобрать наиболее оптимальные параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586933c2",
   "metadata": {},
   "source": [
    "## 4. В чем разница между параметром модели и гиперпараметром алгоритма обучения? Приведите примеры.\n",
    "\n",
    "Параметры модели настраиваются моделью в процессе обучения. Гиперпараметр же с точки зрения модели является константой: он задаётся перед началом обучения и не изменяется в процессе обучения, так как не предполагается, что модель будет его изменять.\n",
    "Цель параметров хранить данные, которыми пользуется модель. Цель гиперпараметров - хранить \"настройки\" модели.\n",
    "\n",
    "Например, параметрами линейной регрессии будут:\n",
    "- веса w;\n",
    "- активная точка градиентного спуска;\n",
    "- предсказанное значение целевой переменной.\n",
    "\n",
    "Гиперпараметрами линейной регрессии будут:\n",
    "- функция ошибки (метрики);\n",
    "- настойки градиентного спуска: вид, шаг, максимальное число итераций, критерий остановки;\n",
    "- функция регуляризации;\n",
    "- размеры учебного, валидационного, тестового множества."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c89b13",
   "metadata": {},
   "source": [
    "## 5. Что может пойти не так, если вы подгоните гиперпараметры модели, на тестовом наборе?\n",
    "\n",
    "Изменение гиперпараметров модели это часть обучения модели. Во время обучения модель пытается оптимально подстроиться под данные, из-за это данные, используемые во время обучения неизбежно просачиваются в неё. Поэтому, если проводить обучение на тестовом сете могут возникнуть следующие проблемы:\n",
    "\n",
    "- Так как тестовый сет меньше учебного, модель легко может переобучиться;\n",
    "- Тестовый сет нужен для независимой оценки модели, если она будет учиться на нём, то результаты теста будут скомпроментированы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31923c",
   "metadata": {},
   "source": [
    "## 6. Что такое перекрестная проверка (cross-validation) и чем она лучше использования одного тестового множества?\n",
    "\n",
    "Обычно для выбора тестового множества используется метод hold-out: сет делится на учебные и тестовые данные в заданной пропорции случайным образом (тоесть на два набора данных: Train_data+Test_data). Другим вариантом разделения является метод cross-validation: сет делится на несколько частей которые чередуют роли учебного и тестового множества.\n",
    "\n",
    "Метод cross-validation даёт более надёжную оценку качества модели, чем hold-out, так как при нём усредняется ошибка модели и дисперсия данных. Однако проведение итераций обучения и теста может быть вычислительно затратным, и поэтому метод обычно применяют либо когда данных достаточно мало, либо при наличии большого количества вычислительных ресурсов. В реальных задачах данных зачастую достаточно много для того, чтобы hold-out давал хорошую оценку качества модели, поэтому cross-validation в больших задачах применяется не очень часто.\n",
    "\n",
    "Наиболее популярным методом cross-validation является k-Fold:\n",
    "1. Датасет разбивается на k одинаковых частей (\"фолдов\"); \n",
    "2. Один фолд становится тестовым сетом, остальные k-1 - учебным;\n",
    "3. Далее проходит k итераций обучения+проверки модели;\n",
    "4. Окончательная оценка модели получается либо усреднением k оценок, либо проверкой на независимом тестовом множестве.\n",
    "\n",
    "Другие методы cross-validation: Leave-P-Out(LPO), Leave-one-out (LOO) и Stratified k-Fold. Последние два основаны на k-Fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba93a43",
   "metadata": {},
   "source": [
    "## 7. Что такое онлайновый режим работы системы машинного обучения?\n",
    "\n",
    "При онлайн обучении модель обучается непрерывно, так как обучение происходит по мере поступления данных. Параметры такого алгоритма обучения обновляются после обучения на каждом отдельном экземпляре данных. \n",
    "\n",
    "Преимущества:\n",
    "1. Обучение можно проводить даже если данных мало, а новуе данные поступают медленно;\n",
    "2. Так как модель постоянно адаптируется, можно работать со сферами где данные быстро устаревают;\n",
    "3. При обучении модель не требует много ресурсов (отдельная итерация обучения проходит быстро и дёшево), так как используется малое количество данных и вычислительных мощностей.\n",
    "\n",
    "Недостатки:\n",
    "1. Нужно следить за качеством и распределением данных при каждом обучении, чтобы модель не выучила что-либо плохое;\n",
    "2. Модель не автономна (для развёртывания её в другом месте, необходимо не только восстанавить её, но и создавать поток новых данных);\n",
    "3. Из-за малого объёма данных модель может не заметить закономерности, позволяющие сделать прогноз более точным. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1095e",
   "metadata": {},
   "source": [
    "## 8. Опишите классификатор по методу ближайших соседей (KNN): в чем заключаются режимы его обучения и предсказания (вывода)?\n",
    "Алгоритм KNN опирается на то, что в некоторых задачах похожие наблюдения расположены близко друг к другу. \n",
    "Пользуясь заранее заданным гиперпараметром k (количество соседей в кластере) и выученными размеченными данными, алгоритм предсказывает значение для не размеченных данных. Для удобства визуализации работу алгоритма можно представить как определение значения в точке путём нахождения и усреднения кластера из k- ближайших точек. \n",
    "\n",
    "#### Обучение\n",
    "Алгоритм выучивает всю обучающую выборку.\n",
    "\n",
    "#### Предсказание\n",
    "1. Алгоритм фокусируется на конкретной точке;\n",
    "2. Вычисляется расстояние между ней и размеченными точками попарно (алгоритм расчёта расстояния - это гиперпараметр; по умолчанию используется алгоритм Евклида, хотя есть и другие варианты: Манхэттенская метрика, Косинусное расстояние и т.д.);\n",
    "3. Получившийся набор расстояний сортируется от наименьшего к наибольшему;\n",
    "4. Первые k записей считаются соседями точки;\n",
    "5. Значением искомой точки является мода значений соседних точек (для задач класссификации), либо усреднённое значение соседних точек (для задач регрессии). По умолчанию вклад каждого соседа одинаков, но если необходимо придать одному из них бОльшее значение, то можно использовать взвешенный KNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd047c7",
   "metadata": {},
   "source": [
    "## 9. Опишите модель линейной регрессии: в чем заключаются режимы ее обучения и предсказания (вывода)?\n",
    "\n",
    "Линейная регрессия основывается на предположении о том, что в наборе данных присутствует линейная закономерность $y = w_1x_1 + w_2x_2 + ... + w_nx_n + w_0$ (где $w_i$ - веса признаков, $w_0$ - свободный вес, $x_i$ - значения признаков, $y$ - целевая переменная).\n",
    "\n",
    "#### Обучение\n",
    "Целью этого этапа является поиск минимального набора весов {$w_0, ..., w_n$}, такого чтобы разница (ошибка) между целевой переменной и предсказанием была наименьшей. Для расчёта ошибки используется метрика Mean Squared Error: \n",
    "$$MSE = \\frac{1}{N}\\sum_{i=1}^N (ȳ_i - y_i)^2$$\n",
    "(где $N$ - количество предсказаний, $ȳ_i$ - предсказанная целевая переменная,$y_i$ - истинная целевая переменная)\n",
    "\n",
    "Задачей модели на всём периоде обучения становится минимизация MSE.\n",
    "\n",
    "Для этого хорошо подходит метод градиентного спуска. Его настройки задаются набором гиперпараметров (вид спуска, шаг спуска, максимальное число итераций, критерий остановки). Принцип алгоритма:\n",
    "\n",
    "1. Инициализируется начальная точка;\n",
    "2. Алгоритм находит градиент в точке - вектор из частных производных, который указывает в сторону увилечения ошибки;\n",
    "3. Используя заданный шаг, значения весов меняются в сторону антиградиента;\n",
    "4. Шаги 2-3 повторяются пока не закончится число итераций отведённое на спуск, либо не будет достигнут критерий остановки.\n",
    "\n",
    "Обучение модели заканчивается тем, что она запоминает полученные веса.\n",
    "\n",
    "При решении задачи регрессии могут возникнуть проблемы: мультиколлинеарность и переобучение, чтобы их избажать нужно:\n",
    "- Перед началом обучения отбросить линейно-зависимые признаки;\n",
    "- Использовать регуляризацию - тоесть функцию, которая наказывает модель за отклонение коэффициентов от нуля (некоторые алгоритмы регуляризации: Lasso Regression, Elastic Net Regression).\n",
    "\n",
    "#### Предсказание\n",
    "\n",
    "Для предсказания результата модель подставляет переданные в неё признаки в формулу с посчитанными весами $y = w_1x_1 + w_2x_2 + ... + w_nx_n + w_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810db285",
   "metadata": {},
   "source": [
    "## 10. В чем заключается разница между обучением с учителем и обучением без привлечения учителя? Какие ещё есть «промежуточные» типы обучения. \n",
    "Алгоритм обучения с учителем (Supervised Learning) предполагает, что учебные данные уже размечены, в таком случае модель знает каково целевое значение для каждого наблюдения в обучающих данных. Задачей модели является нахождение правила, позволяющего получить целевое значение.\n",
    "К таким алгоритмам относятся: \n",
    "- классификация (размечен класс); \n",
    "- регрессия (размечено численное значение), \n",
    "\n",
    "В отличие от него алгоритм обучения без учителя (Unsupervised Learning) используется там, где нет заранее размеченных данных. Задачей является поиск закономерностей и структур в наборах данных. \n",
    "К таким алгоритмам относятся: \n",
    "- кластеризация (задача разбиения, а так же нахождения обычности) - в отличие от классификации не известен признак для разделения и не известно количество классов; \n",
    "- уменьшение размерности данных (в которых много признаков); \n",
    "- обнаружение аномалий (кластеризация на \"обычные данные\" и \"отклонения\");\n",
    "- поиск структур (уменьшение размерности графических данных с сохранением необходимых очертаний);\n",
    "- поиск ассоциативных связей.\n",
    "\n",
    "Помимо обучения с учителем и без можно выделить ещё два алгоритма:\n",
    "#### 1. Обучение с частичным привлечением учителя (Semi-Supervised Learning)\n",
    "Это алгоритмы, которые комбинируют методы с учителем и без. Как правило такие алгоритмы используют малое количество размеченных, и огромное количество неразмеченных данных (так как разметка данных ресурсозатратна). Пример алгоритма: сначала происходит кластеризация части данных, а потом на базе известных кластеров классификация всех данных.\n",
    "\n",
    "#### 2. Обучение с подкреплением (Reinforcement Learning)\n",
    "Этот алгоритм обучается за счёт постоянного взаимодействия со средой. В ответ на свои действия он получает варьирующееся вознаграждение, либо наказание. Целью алгоритма являеся максимизация первого и минимизация второго.\n",
    "У такого алгоритма есть недостаток: он плохо работает с задачами, действия которых на раннем этапе имеют долгосрочные последствия для общей цели, а так же с задачами в которых лучше пожертвовать немедленным вознаграждением, в пользу бОльшего, но отсроченного вознаграждения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f83d5",
   "metadata": {},
   "source": [
    "## 11. Что такое переобучение?\n",
    "Переобучением называется ситуация, когда модель \"заучила\" решение к задачам для учебных (и, возможно даже, для тестовых) данных, вместо того чтобы найти существующий в данных тренд. Такая модель имеет черезывычайно высокую точность на учебных данных, но не способна решить задачу для новых данных.\n",
    "\n",
    "Переобучение появляется, из-за того что модель приписывает имеющимся данным слишком большие веса, это происходит когда модель многократно учится и тестируется на одних и тех же данных.\n",
    "\n",
    "Методы борьбы с переобучением: увеличение количества учебных данных, использование разных наборов данных для теста, регуляризация (штраф за высокие веса)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91b666",
   "metadata": {},
   "source": [
    "## 12. Опишите кратко метод работы дерева решений и ансамбля таких деревьев в режиме взаимного усиления (мы знаем его как «бустинг»)\n",
    "\n",
    "В основе дерева решений лежит принцип жадной максимизации – на каждом шаге выбирается тот признак, при разделении по которому прирост информации оказывается наибольшим. Дальше процедура повторяется рекурсивно, пока количество возможных для объекта классов не сведётся к минимуму. Решающие деревья являются подвидом алгоритмов с учителем, они могут решать задачи классификации и регрессии: в первом случае дерево осуществляет поиск класса или набора классов, а во втором — интервал целевой переменной.\n",
    "\n",
    "Бустинг – это один из метод Ансамблевого обучения, при таком методе несколько слабых моделей поочерёдно работают над одной задачей чтобы достичь высокой точности. Основная идея бустинга – обучать каждую следующую модель на ошибках предыдущих моделей, тоесть данные на которых ошиблась предыдущая модель снаибольшей вероятностью попадут в выборку для будующих моделей. Популярные алгоритмы бустинга CatBoost и XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df82d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
